{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1451e8b4",
   "metadata": {},
   "source": [
    "# ETAPA 1 - Preparação dos Dados\n",
    "\n",
    "### #=====Vizualização dos Dados======#\n",
    "\n",
    "Nesta etapa, foi realizada a leitura de todos os arquivos CSV da base de dados do Olist, localizados na pasta data/raw/.\n",
    "Utilizei um dicionário (file_map) para mapear nomes intuitivos aos nomes dos arquivos. Em seguida, carreguei os dados com pandas.read_csv() e armazenamos os DataFrames em um dicionário (dfs) para facilitar o acesso e manipulação. Por fim, foi exibida as primeiras linhas de cada tabela para verificar se os dados foram carregados corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#===Definindo o caminho dos arquivos brutos===#\n",
    "raw_path = '../data/raw/'\n",
    "\n",
    "#===Mapeando os arquivos em um dicionário para facilitar o carregamento===#\n",
    "file_map = {\n",
    "    \"orders\": \"olist_orders_dataset.csv\",\n",
    "    \"customers\": \"olist_customers_dataset.csv\",\n",
    "    \"products\": \"olist_products_dataset.csv\",\n",
    "    \"sellers\": \"olist_sellers_dataset.csv\",\n",
    "    \"order_items\": \"olist_order_items_dataset.csv\",\n",
    "    \"order_reviews\": \"olist_order_reviews_dataset.csv\",\n",
    "    \"order_payments\": \"olist_order_payments_dataset.csv\",\n",
    "    \"geolocation\": \"olist_geolocation_dataset.csv\",\n",
    "    \"product_translation\": \"product_category_name_translation.csv\"\n",
    "}\n",
    "\n",
    "#===Carregando todos os arquivos em dataframes===#\n",
    "dfs = {name: pd.read_csv(os.path.join(raw_path, filename)) for name, filename in file_map.items()}\n",
    "\n",
    "#===Exibindo os primeiros registros de cada dataset===#\n",
    "for name, df in dfs.items():\n",
    "    print(f\"\\n{name.upper()}:\\n\")\n",
    "    display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c510b40",
   "metadata": {},
   "source": [
    "### #======Limpeza e Normalização dos Dados======#\n",
    "\n",
    "Nesta etapa, apliquei duas funções auxiliares para padronizar e limpar todos os DataFrames carregados:\n",
    "\n",
    "- normalize_columns(): transforma os nomes das colunas para minúsculo, substitui espaços e hífens por underscores (_), deixando o padrão mais limpo e consistente.\n",
    "\n",
    "- clean_df(): remove linhas duplicadas, linhas e colunas totalmente vazias.\n",
    "\n",
    "Após aplicar essas funções a todos os DataFrames, salvei os arquivos limpos na pasta data/processed/, organizando o fluxo de dados para etapas futuras da análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Função que normaliza nomes de colunas===#\n",
    "def normalize_columns(df):\n",
    "    return df.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\"))\n",
    "\n",
    "#===Função de limpeza básica===#\n",
    "def clean_df(df):\n",
    "    df = df.drop_duplicates()           #->Remove duplicatas\n",
    "    df = df.dropna(how='all')           #->Remove linhas totalmente vazias\n",
    "    df = df.dropna(axis=1, how='all')   #->Remove colunas totalmente vazias\n",
    "    return df\n",
    "\n",
    "#===Aplicando limpeza e normalização em todos os dataframes===#\n",
    "for name in dfs:\n",
    "    dfs[name] = normalize_columns(dfs[name])\n",
    "    dfs[name] = clean_df(dfs[name])\n",
    "\n",
    "#===Correções específicas para colunas com erros de digitação===#\n",
    "dfs[\"products\"].rename(columns={\n",
    "    \"product_name_lenght\": \"product_name_length\",\n",
    "    \"product_description_lenght\": \"product_description_length\"\n",
    "}, inplace=True)\n",
    "\n",
    "#===Salvando os dados limpos em CSVs===#\n",
    "processed_path = \"../data/processed/\"\n",
    "if os.path.exists(processed_path) and not os.path.isdir(processed_path):\n",
    "    os.remove(processed_path)\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    df.to_csv(os.path.join(processed_path, f\"{name}.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0524b8",
   "metadata": {},
   "source": [
    "### #======Criação do banco de dados relacional======#\n",
    "\n",
    "-Defini as tabelas com chaves primárias e estrangeiras, respeitando as relações entre os dados (ex: order_items referenciando orders, products e sellers).\n",
    "\n",
    "-Inseri todos os dados do dicionário dfs diretamente nas tabelas do banco, utilizando pandas.to_sql() com if_exists=\"append\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "#===Caminho para salvar o banco SQLite===#\n",
    "processed_path = \"../data/processed\"\n",
    "db_path = os.path.join(processed_path, \"olist_ecommerce.db\")\n",
    "\n",
    "#===Conexão com o banco===#\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#===Criação das tabelas com chaves primárias e estrangeiras===#\n",
    "cursor.executescript(\"\"\"\n",
    "DROP TABLE IF EXISTS customers;\n",
    "DROP TABLE IF EXISTS sellers;\n",
    "DROP TABLE IF EXISTS products;\n",
    "DROP TABLE IF EXISTS orders;\n",
    "DROP TABLE IF EXISTS order_items;\n",
    "DROP TABLE IF EXISTS order_reviews;\n",
    "DROP TABLE IF EXISTS order_payments;\n",
    "DROP TABLE IF EXISTS geolocation;\n",
    "DROP TABLE IF EXISTS product_translation;\n",
    "\n",
    "CREATE TABLE customers (\n",
    "    customer_id TEXT PRIMARY KEY,\n",
    "    customer_unique_id TEXT,\n",
    "    customer_zip_code_prefix INTEGER,\n",
    "    customer_city TEXT,\n",
    "    customer_state TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE sellers (\n",
    "    seller_id TEXT PRIMARY KEY,\n",
    "    seller_zip_code_prefix INTEGER,\n",
    "    seller_city TEXT,\n",
    "    seller_state TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE products (\n",
    "    product_id TEXT PRIMARY KEY,\n",
    "    product_category_name TEXT,\n",
    "    product_name_length REAL,\n",
    "    product_description_length REAL,\n",
    "    product_photos_qty REAL,\n",
    "    product_weight_g REAL,\n",
    "    product_length_cm REAL,\n",
    "    product_height_cm REAL,\n",
    "    product_width_cm REAL\n",
    ");\n",
    "\n",
    "CREATE TABLE orders (\n",
    "    order_id TEXT PRIMARY KEY,\n",
    "    customer_id TEXT,\n",
    "    order_status TEXT,\n",
    "    order_purchase_timestamp TEXT,\n",
    "    order_approved_at TEXT,\n",
    "    order_delivered_carrier_date TEXT,\n",
    "    order_delivered_customer_date TEXT,\n",
    "    order_estimated_delivery_date TEXT,\n",
    "    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE order_items (\n",
    "    order_id TEXT,\n",
    "    order_item_id INTEGER,\n",
    "    product_id TEXT,\n",
    "    seller_id TEXT,\n",
    "    shipping_limit_date TEXT,\n",
    "    price REAL,\n",
    "    freight_value REAL,\n",
    "    PRIMARY KEY (order_id, order_item_id),\n",
    "    FOREIGN KEY (order_id) REFERENCES orders(order_id),\n",
    "    FOREIGN KEY (product_id) REFERENCES products(product_id),\n",
    "    FOREIGN KEY (seller_id) REFERENCES sellers(seller_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE order_reviews (\n",
    "    review_id TEXT PRIMARY KEY,\n",
    "    order_id TEXT,\n",
    "    review_score INTEGER,\n",
    "    review_comment_title TEXT,\n",
    "    review_comment_message TEXT,\n",
    "    review_creation_date TEXT,\n",
    "    review_answer_timestamp TEXT,\n",
    "    FOREIGN KEY (order_id) REFERENCES orders(order_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE order_payments (\n",
    "    order_id TEXT,\n",
    "    payment_sequential INTEGER,\n",
    "    payment_type TEXT,\n",
    "    payment_installments INTEGER,\n",
    "    payment_value REAL,\n",
    "    FOREIGN KEY (order_id) REFERENCES orders(order_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE geolocation (\n",
    "    geolocation_zip_code_prefix INTEGER,\n",
    "    geolocation_lat REAL,\n",
    "    geolocation_lng REAL,\n",
    "    geolocation_city TEXT,\n",
    "    geolocation_state TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE product_translation (\n",
    "    product_category_name TEXT PRIMARY KEY,\n",
    "    product_category_name_english TEXT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "#===Removendo duplicatas com base nas chaves primárias antes da inserção===#\n",
    "dfs[\"customers\"].drop_duplicates(subset=[\"customer_id\"], inplace=True)\n",
    "dfs[\"sellers\"].drop_duplicates(subset=[\"seller_id\"], inplace=True)\n",
    "dfs[\"products\"].drop_duplicates(subset=[\"product_id\"], inplace=True)\n",
    "dfs[\"orders\"].drop_duplicates(subset=[\"order_id\"], inplace=True)\n",
    "dfs[\"order_reviews\"].drop_duplicates(subset=[\"review_id\"], inplace=True)\n",
    "dfs[\"order_items\"].drop_duplicates(subset=[\"order_id\", \"order_item_id\"], inplace=True)\n",
    "dfs[\"product_translation\"].drop_duplicates(subset=[\"product_category_name\"], inplace=True)\n",
    "\n",
    "# Inserção dos dados em cada tabela\n",
    "for name, df in dfs.items():\n",
    "    df.to_sql(name, conn, if_exists=\"append\", index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141a9e7",
   "metadata": {},
   "source": [
    "### #======Verificação do Banco de Dados======#\n",
    "\n",
    "Listei todas as tabelas criadas no SQLite para garantir que foram geradas corretamente.\n",
    "\n",
    "Também executei um JOIN entre orders, customers e order_payments para validar os relacionamentos e conferir se os dados estão integrados como esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Conectando ao banco SQLite===#\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"../data/processed/olist_ecommerce.db\")\n",
    "\n",
    "# Conferindo se as tabelas foram criadas no banco\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "tables\n",
    "\n",
    "# Validando relacionamento com SQL JOIN\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    o.order_id,\n",
    "    o.order_purchase_timestamp,\n",
    "    c.customer_state,\n",
    "    p.payment_value\n",
    "FROM orders o\n",
    "JOIN customers c ON o.customer_id = c.customer_id\n",
    "JOIN order_payments p ON o.order_id = p.order_id\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e7c291",
   "metadata": {},
   "source": [
    "# ETAPA 2 - Análise Exploratória de Dados\n",
    "\n",
    "### a) Qual o volume de pedidos por mês? Existe sazonalidade nas vendas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Conectando ao banco SQLite onde estão os dados organizados===#\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(\"../data/processed/olist_ecommerce.db\")  #->Abre conexão com o banco de dados\n",
    "\n",
    "#===Consulta SQL para contar quantos pedidos foram feitos por mês===#\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    strftime('%Y-%m', order_purchase_timestamp) AS order_month, \n",
    "    COUNT(order_id) AS total_orders                             \n",
    "FROM orders\n",
    "GROUP BY order_month\n",
    "ORDER BY order_month;\n",
    "\"\"\"\n",
    "\n",
    "#===Lê o resultado da query e transforma em DataFrame===#\n",
    "df_orders_by_month = pd.read_sql(query, conn)\n",
    "\n",
    "#===Visualizando os primeiros resultados===#\n",
    "df_orders_by_month.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a829e320",
   "metadata": {},
   "source": [
    "Com a query acima, conseguimos agrupar os pedidos por mês utilizando a função `strftime('%Y-%m', ...)`.  \n",
    "Esse agrupamento nos permitirá identificar flutuações mensais e possíveis padrões sazonais nas vendas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Importando bibliotecas para visualização===#\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#===Criando gráfico de linha para visualizar a evolução dos pedidos mês a mês===#\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.lineplot(data=df_orders_by_month, x=\"order_month\", y=\"total_orders\", marker=\"o\")  #->Gráfico de linha com marcação nos pontos\n",
    "plt.xticks(rotation=45)                                                                #->Rotaciona os rótulos do eixo x\n",
    "plt.title(\"Volume de Pedidos por Mês\")                                                 #->Título do gráfico\n",
    "plt.xlabel(\"Mês\")\n",
    "plt.ylabel(\"Número de Pedidos\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
