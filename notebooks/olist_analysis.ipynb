{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1451e8b4",
   "metadata": {},
   "source": [
    "# ETAPA 1 - Preparação dos Dados\n",
    "\n",
    "### #=====Vizualização dos Dados======#\n",
    "\n",
    "> **Nota:** Toda a preparação dos dados também está disponível no script `src/data_preprocessing.py`, com a mesma lógica descrita aqui.  \n",
    "> No entanto, optamos por documentar e rodar tudo diretamente neste notebook (`olist_analysis.ipynb`) para fins de explicação detalhada e rastreabilidade.\n",
    "\n",
    "Nesta etapa, foi realizada a leitura de todos os arquivos CSV da base de dados do Olist, localizados na pasta data/raw/.\n",
    "Utilizei um dicionário (file_map) para mapear nomes intuitivos aos nomes dos arquivos. Em seguida, carreguei os dados com pandas.read_csv() e armazenamos os DataFrames em um dicionário (dfs) para facilitar o acesso e manipulação. Por fim, foi exibida as primeiras linhas de cada tabela para verificar se os dados foram carregados corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#===Definindo o caminho dos arquivos brutos===#\n",
    "raw_path = '../data/raw/'\n",
    "\n",
    "#===Mapeando os arquivos em um dicionário para facilitar o carregamento===#\n",
    "file_map = {\n",
    "    \"orders\": \"olist_orders_dataset.csv\",\n",
    "    \"customers\": \"olist_customers_dataset.csv\",\n",
    "    \"products\": \"olist_products_dataset.csv\",\n",
    "    \"sellers\": \"olist_sellers_dataset.csv\",\n",
    "    \"order_items\": \"olist_order_items_dataset.csv\",\n",
    "    \"order_reviews\": \"olist_order_reviews_dataset.csv\",\n",
    "    \"order_payments\": \"olist_order_payments_dataset.csv\",\n",
    "    \"geolocation\": \"olist_geolocation_dataset.csv\",\n",
    "    \"product_translation\": \"product_category_name_translation.csv\"\n",
    "}\n",
    "\n",
    "#===Carregando todos os arquivos em dataframes===#\n",
    "dfs = {name: pd.read_csv(os.path.join(raw_path, filename)) for name, filename in file_map.items()}\n",
    "\n",
    "#===Exibindo os primeiros registros de cada dataset===#\n",
    "for name, df in dfs.items():\n",
    "    print(f\"\\n{name.upper()}:\\n\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c510b40",
   "metadata": {},
   "source": [
    "### #======Limpeza e Normalização dos Dados======#\n",
    "\n",
    "Nesta etapa, apliquei duas funções auxiliares para padronizar e limpar todos os DataFrames carregados:\n",
    "\n",
    "- normalize_columns(): transforma os nomes das colunas para minúsculo, substitui espaços e hífens por underscores (_), deixando o padrão mais limpo e consistente.\n",
    "\n",
    "- clean_df(): remove linhas duplicadas, linhas e colunas totalmente vazias.\n",
    "\n",
    "Após aplicar essas funções a todos os DataFrames, salvei os arquivos limpos na pasta data/processed/, organizando o fluxo de dados para etapas futuras da análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Função que normaliza nomes de colunas===#\n",
    "def normalize_columns(df):\n",
    "    return df.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\"))\n",
    "\n",
    "#===Função de limpeza básica===#\n",
    "def clean_df(df):\n",
    "    df = df.drop_duplicates()           #->Remove duplicatas\n",
    "    df = df.dropna(how='all')           #->Remove linhas totalmente vazias\n",
    "    df = df.dropna(axis=1, how='all')   #->Remove colunas totalmente vazias\n",
    "    return df\n",
    "\n",
    "#===Aplicando limpeza e normalização em todos os dataframes===#\n",
    "for name in dfs:\n",
    "    dfs[name] = normalize_columns(dfs[name])\n",
    "    dfs[name] = clean_df(dfs[name])\n",
    "\n",
    "#===Correções específicas para colunas com erros de digitação===#\n",
    "dfs[\"products\"].rename(columns={\n",
    "    \"product_name_lenght\": \"product_name_length\",\n",
    "    \"product_description_lenght\": \"product_description_length\"\n",
    "}, inplace=True)\n",
    "\n",
    "#===Salvando os dados limpos em CSVs===#\n",
    "processed_path = \"../data/processed/\"\n",
    "if os.path.exists(processed_path) and not os.path.isdir(processed_path):\n",
    "    os.remove(processed_path)\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "for name, df in dfs.items():\n",
    "    df.to_csv(os.path.join(processed_path, f\"{name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0524b8",
   "metadata": {},
   "source": [
    "### #======Criação do banco de dados relacional======#\n",
    "\n",
    "- Defini as tabelas com chaves primárias e estrangeiras, respeitando as relações entre os dados (ex: order_items referenciando orders, products e sellers).\n",
    "\n",
    "- Inseri todos os dados do dicionário dfs diretamente nas tabelas do banco, utilizando pandas.to_sql() com if_exists=\"append\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "\n",
    "#===Caminho para salvar o banco SQLite===#\n",
    "processed_path = \"../data/processed\"\n",
    "db_path = os.path.join(processed_path, \"olist_ecommerce.db\")\n",
    "\n",
    "#===Conexão com o banco===#\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "#===Criação das tabelas com chaves primárias e estrangeiras===#\n",
    "cursor.executescript(\"\"\"\n",
    "DROP TABLE IF EXISTS customers;\n",
    "DROP TABLE IF EXISTS sellers;\n",
    "DROP TABLE IF EXISTS products;\n",
    "DROP TABLE IF EXISTS orders;\n",
    "DROP TABLE IF EXISTS order_items;\n",
    "DROP TABLE IF EXISTS order_reviews;\n",
    "DROP TABLE IF EXISTS order_payments;\n",
    "DROP TABLE IF EXISTS geolocation;\n",
    "DROP TABLE IF EXISTS product_translation;\n",
    "\n",
    "CREATE TABLE customers (\n",
    "    customer_id TEXT PRIMARY KEY,\n",
    "    customer_unique_id TEXT,\n",
    "    customer_zip_code_prefix INTEGER,\n",
    "    customer_city TEXT,\n",
    "    customer_state TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE sellers (\n",
    "    seller_id TEXT PRIMARY KEY,\n",
    "    seller_zip_code_prefix INTEGER,\n",
    "    seller_city TEXT,\n",
    "    seller_state TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE products (\n",
    "    product_id TEXT PRIMARY KEY,\n",
    "    product_category_name TEXT,\n",
    "    product_name_length REAL,\n",
    "    product_description_length REAL,\n",
    "    product_photos_qty REAL,\n",
    "    product_weight_g REAL,\n",
    "    product_length_cm REAL,\n",
    "    product_height_cm REAL,\n",
    "    product_width_cm REAL\n",
    ");\n",
    "\n",
    "CREATE TABLE orders (\n",
    "    order_id TEXT PRIMARY KEY,\n",
    "    customer_id TEXT,\n",
    "    order_status TEXT,\n",
    "    order_purchase_timestamp TEXT,\n",
    "    order_approved_at TEXT,\n",
    "    order_delivered_carrier_date TEXT,\n",
    "    order_delivered_customer_date TEXT,\n",
    "    order_estimated_delivery_date TEXT,\n",
    "    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE order_items (\n",
    "    order_id TEXT,\n",
    "    order_item_id INTEGER,\n",
    "    product_id TEXT,\n",
    "    seller_id TEXT,\n",
    "    shipping_limit_date TEXT,\n",
    "    price REAL,\n",
    "    freight_value REAL,\n",
    "    PRIMARY KEY (order_id, order_item_id),\n",
    "    FOREIGN KEY (order_id) REFERENCES orders(order_id),\n",
    "    FOREIGN KEY (product_id) REFERENCES products(product_id),\n",
    "    FOREIGN KEY (seller_id) REFERENCES sellers(seller_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE order_reviews (\n",
    "    review_id TEXT PRIMARY KEY,\n",
    "    order_id TEXT,\n",
    "    review_score INTEGER,\n",
    "    review_comment_title TEXT,\n",
    "    review_comment_message TEXT,\n",
    "    review_creation_date TEXT,\n",
    "    review_answer_timestamp TEXT,\n",
    "    FOREIGN KEY (order_id) REFERENCES orders(order_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE order_payments (\n",
    "    order_id TEXT,\n",
    "    payment_sequential INTEGER,\n",
    "    payment_type TEXT,\n",
    "    payment_installments INTEGER,\n",
    "    payment_value REAL,\n",
    "    FOREIGN KEY (order_id) REFERENCES orders(order_id)\n",
    ");\n",
    "\n",
    "CREATE TABLE geolocation (\n",
    "    geolocation_zip_code_prefix INTEGER,\n",
    "    geolocation_lat REAL,\n",
    "    geolocation_lng REAL,\n",
    "    geolocation_city TEXT,\n",
    "    geolocation_state TEXT\n",
    ");\n",
    "\n",
    "CREATE TABLE product_translation (\n",
    "    product_category_name TEXT PRIMARY KEY,\n",
    "    product_category_name_english TEXT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "#===Removendo duplicatas com base nas chaves primárias antes da inserção===#\n",
    "dfs[\"customers\"].drop_duplicates(subset=[\"customer_id\"], inplace=True)\n",
    "dfs[\"sellers\"].drop_duplicates(subset=[\"seller_id\"], inplace=True)\n",
    "dfs[\"products\"].drop_duplicates(subset=[\"product_id\"], inplace=True)\n",
    "dfs[\"orders\"].drop_duplicates(subset=[\"order_id\"], inplace=True)\n",
    "dfs[\"order_reviews\"].drop_duplicates(subset=[\"review_id\"], inplace=True)\n",
    "dfs[\"order_items\"].drop_duplicates(subset=[\"order_id\", \"order_item_id\"], inplace=True)\n",
    "dfs[\"product_translation\"].drop_duplicates(subset=[\"product_category_name\"], inplace=True)\n",
    "\n",
    "# Inserção dos dados em cada tabela\n",
    "for name, df in dfs.items():\n",
    "    df.to_sql(name, conn, if_exists=\"append\", index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141a9e7",
   "metadata": {},
   "source": [
    "### #======Verificação do Banco de Dados======#\n",
    "\n",
    "Listei todas as tabelas criadas no SQLite para garantir que foram geradas corretamente.\n",
    "\n",
    "Também executei um JOIN entre orders, customers e order_payments para validar os relacionamentos e conferir se os dados estão integrados como esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Conectando ao banco SQLite===#\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"../data/processed/olist_ecommerce.db\")\n",
    "\n",
    "#===Conferindo se as tabelas foram criadas no banco===#\n",
    "tables = pd.read_sql(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "tables\n",
    "\n",
    "#===Validando relacionamento com SQL JOIN===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    o.order_id,\n",
    "    o.order_purchase_timestamp,\n",
    "    c.customer_state,\n",
    "    p.payment_value\n",
    "FROM orders o\n",
    "JOIN customers c ON o.customer_id = c.customer_id\n",
    "JOIN order_payments p ON o.order_id = p.order_id\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e7c291",
   "metadata": {},
   "source": [
    "# ETAPA 2 - Análise Exploratória de Dados\n",
    "\n",
    "### (a) Qual o volume de pedidos por mês? Existe sazonalidade nas vendas?\n",
    "\n",
    "- Extrair o mês (%Y-%m) da data de compra (order_purchase_timestamp)\n",
    "- Contar o número de pedidos agrupados por mês\n",
    "- Plotar a série temporal para visualizar padrões de crescimento e sazonalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Conectando ao banco SQLite onde estão os dados organizados===#\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(\"../data/processed/olist_ecommerce.db\")  #->Abre conexão com o banco de dados\n",
    "\n",
    "#===Consulta SQL para contar quantos pedidos foram feitos por mês===#\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    strftime('%Y-%m', order_purchase_timestamp) AS order_month, \n",
    "    COUNT(order_id) AS total_orders                             \n",
    "FROM orders\n",
    "GROUP BY order_month\n",
    "ORDER BY order_month;\n",
    "\"\"\"\n",
    "\n",
    "#===Lê o resultado da query e transforma em DataFrame===#\n",
    "df_orders_by_month = pd.read_sql(query, conn)\n",
    "\n",
    "#===Visualizando os primeiros resultados===#\n",
    "df_orders_by_month.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a829e320",
   "metadata": {},
   "source": [
    "Com a query acima, os pedidos serão agrupaddos por mês utilizando a função `strftime('%Y-%m', ...)`.  \n",
    "Esse agrupamento permitirá identificar flutuações mensais e possíveis padrões sazonais nas vendas.  \n",
    "Abaixo, segue um  gráfico de linha básico com seaborn para identificar essas flutuações e possíveis padrões nas vendas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Importando bibliotecas para visualização===#\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#===Criando gráfico de linha para visualizar a evolução dos pedidos mês a mês===#\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.lineplot(data=df_orders_by_month, x=\"order_month\", y=\"total_orders\", marker=\"o\")  #->Gráfico de linha com marcação nos pontos\n",
    "plt.xticks(rotation=45)                                                                #->Rotaciona os rótulos do eixo x\n",
    "plt.title(\"Volume de Pedidos por Mês\")                                                 #->Título do gráfico\n",
    "plt.xlabel(\"Mês\")\n",
    "plt.ylabel(\"Número de Pedidos\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a262c4",
   "metadata": {},
   "source": [
    "### (b) Qual a distribuição do tempo de entrega dos pedidos?\n",
    "\n",
    "- Calcular a diferença entre a data de entrega (order_delivered_customer_date) e a data da compra (order_purchase_timestamp)\n",
    "- Converter para número de dias\n",
    "- Visualizar com histograma para entender os tempos típicos e outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0073d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Consulta SQL para pegar a data da compra e da entrega do pedido===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    order_id,\n",
    "    order_purchase_timestamp,\n",
    "    order_delivered_customer_date\n",
    "FROM orders\n",
    "WHERE order_delivered_customer_date IS NOT NULL\n",
    "AND order_purchase_timestamp IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "#===Executando a query e armazenando o resultado em um DataFrame===#\n",
    "df_delivery = pd.read_sql(query, conn)\n",
    "\n",
    "#===Convertendo as colunas de data para o formato datetime do pandas===#\n",
    "df_delivery['order_purchase_timestamp'] = pd.to_datetime(df_delivery['order_purchase_timestamp'])\n",
    "df_delivery['order_delivered_customer_date'] = pd.to_datetime(df_delivery['order_delivered_customer_date'])\n",
    "\n",
    "#===Calculando o tempo de entrega em dias===#\n",
    "df_delivery['delivery_time_days'] = (df_delivery['order_delivered_customer_date'] - df_delivery['order_purchase_timestamp']).dt.days\n",
    "\n",
    "#===Visualizando os primeiros valores da nova coluna criada===#\n",
    "df_delivery[['order_id', 'delivery_time_days']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dbff3",
   "metadata": {},
   "source": [
    "A distribuição mostra o número de dias entre a compra e a entrega dos pedidos.  \n",
    "Esse dado será útil para a análise de predição de atrasos (Etapa 3) e também para investigar a satisfação dos clientes.  \n",
    "No gráfico abaixo, está um histograma com curva de densidade que ilustra claramente essa distribuição de tempos de entrega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Visualizando a distribuição dos tempos de entrega com histograma===#\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df_delivery['delivery_time_days'], bins=30, kde=True)  #->Histograma com 30 faixas e curva de densidade\n",
    "plt.title(\"Distribuição do Tempo de Entrega dos Pedidos (em dias)\")\n",
    "plt.xlabel(\"Dias\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da594868",
   "metadata": {},
   "source": [
    "### (c) Qual a relação entre o valor do frete e a distância de entrega? \n",
    "- Pegar as médias de lat/lng por zip_code_prefix\n",
    "- Juntar customers + sellers + order_items\n",
    "- Calcular a distância com a fórmula de Haversine\n",
    "- Ver a relação entre freight_value e distância\n",
    "\n",
    "**Desafios de performance:**\n",
    "- A tabela geolocation tem dados duplicados por CEP, então precisamos agrupar\n",
    "- A fórmula de Haversine é pesada, então vamos aplicar só depois do SELECT\n",
    "- Para acelerar tudo, vamos criar uma VIEW e índices no banco SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1749ef74",
   "metadata": {},
   "source": [
    "#### Criando uma VIEW no banco para calcular a média de latitude/longitude por CEP\n",
    "\n",
    "Em vez de calcular a média de coordenadas geográficas toda vez que rodar a query, criei uma VIEW chamada geo_avg.  \n",
    "Ela já deixa os dados prontos e agrupados por `zip_code_prefix`, facilitando os JOINs e melhorando o desempenho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d9e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criação de VIEW: média da latitude e longitude por CEP para evitar recalcular isso várias vezes===#\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.executescript(\"\"\"\n",
    "DROP VIEW IF EXISTS geo_avg;\n",
    "CREATE VIEW geo_avg AS\n",
    "SELECT \n",
    "    geolocation_zip_code_prefix,\n",
    "    AVG(geolocation_lat) AS lat,\n",
    "    AVG(geolocation_lng) AS lng\n",
    "FROM geolocation\n",
    "GROUP BY geolocation_zip_code_prefix;\n",
    "\"\"\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade5c9f1",
   "metadata": {},
   "source": [
    "#### Criando índices para acelerar os JOINs\n",
    "\n",
    "Índices froma criados nas colunas que participam de JOINs nas tabelas principais.  \n",
    "Isso melhora a velocidade de resposta, especialmente com conjuntos de dados maiores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d5b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando índices para acelerar os JOINs nas colunas mais usadas===#\n",
    "cursor.executescript(\"\"\"\n",
    "CREATE INDEX IF NOT EXISTS idx_customer_zip ON customers(customer_zip_code_prefix);\n",
    "CREATE INDEX IF NOT EXISTS idx_seller_zip ON sellers(seller_zip_code_prefix);\n",
    "CREATE INDEX IF NOT EXISTS idx_geo_zip ON geolocation(geolocation_zip_code_prefix);\n",
    "CREATE INDEX IF NOT EXISTS idx_order_customer ON orders(customer_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_order_item_order ON order_items(order_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_order_item_seller ON order_items(seller_id);\n",
    "\"\"\")\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20739e9a",
   "metadata": {},
   "source": [
    "#### Rodando a query para coletar frete e coordenadas de cliente e vendedor\n",
    "\n",
    "Todos os JOINs necessários com a geo_avg para pegar a posição média do cliente e do vendedor.  \n",
    "Aplicando tambeém um LIMIT de 5000 linhas e um filtro para o estado de SP para testar com mais rapidez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Query otimizada: JOIN com a VIEW geo_avg ao invés de recalcular os AVG de coordenadas===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    o.order_id,\n",
    "    o.seller_id,\n",
    "    o.freight_value,\n",
    "    gc.lat AS customer_lat,\n",
    "    gc.lng AS customer_lng,\n",
    "    gs.lat AS seller_lat,\n",
    "    gs.lng AS seller_lng\n",
    "FROM order_items o\n",
    "JOIN orders ord ON o.order_id = ord.order_id\n",
    "JOIN customers c ON ord.customer_id = c.customer_id\n",
    "JOIN sellers s ON o.seller_id = s.seller_id\n",
    "JOIN geo_avg gc ON c.customer_zip_code_prefix = gc.geolocation_zip_code_prefix\n",
    "JOIN geo_avg gs ON s.seller_zip_code_prefix = gs.geolocation_zip_code_prefix\n",
    "WHERE c.customer_state = 'SP'\n",
    "LIMIT 5000;\n",
    "\"\"\"\n",
    "\n",
    "#===Executando a consulta e armazenando no DataFrame===#\n",
    "df_dist = pd.read_sql(query, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2648fc",
   "metadata": {},
   "source": [
    "#### Calculando a distância entre cliente e vendedor\n",
    "\n",
    "Calculei a distância entre cliente e vendedor utilizando a fórmula de Haversine que, baseado em trigonometria esfériaca, serve para estima a distância entre dois pontos na superfície de uma esfera, levando em consideração a curvatura da Terra.  \n",
    "A aplicação foi feita linha a linha no DataFrame usando .apply() do pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3be520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Fórmula de Haversine: calcula a distância entre dois pontos do globo===#\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  #-> raio da Terra em km\n",
    "    dlat = radians(lat2 - lat1) #-> Converte graus para radianos\n",
    "    dlon = radians(lon2 - lon1)\n",
    "\n",
    "    #===Fórmula de Haversine===#\n",
    "    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "#=== Criação da coluna com a distância estimada em km===#\n",
    "df_dist['distance_km'] = df_dist.apply(\n",
    "    lambda row: haversine(\n",
    "        row[\"customer_lat\"], row[\"customer_lng\"], \n",
    "        row[\"seller_lat\"], row[\"seller_lng\"]),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d131d6b5",
   "metadata": {},
   "source": [
    "A visualização sugere que há uma correlação entre a distância e o valor do frete.  \n",
    "Para distâncias maiores, o frete tende a ser mais alto, o que é esperado.  \n",
    "Contudo, há dispersão indicando que outros fatores também afetam o custo de entrega (peso, cidade, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando gráfico para visualizar a relação entre frete e distância===#\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=df_dist, x=\"distance_km\", y=\"freight_value\", alpha=0.5)\n",
    "plt.title(\"Relação entre Distância e Valor do Frete\")\n",
    "plt.xlabel(\"Distância estimada (km)\")\n",
    "plt.ylabel(\"Frete (R$)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142f69d",
   "metadata": {},
   "source": [
    "###  (d) Categorias de produtos mais vendidas em faturamento\n",
    "- Juntar order_items, products e product_category_name_translation\n",
    "- Somar o valor total (price) vendido por categoria\n",
    "- Ordenar do maior para o menor faturamento\n",
    "- Visualizar as top 10 com gráfico de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da981fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Consulta para somar o valor total vendido por categoria (já traduzida)===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    pt.product_category_name_english AS category,\n",
    "    SUM(oi.price) AS total_revenue\n",
    "FROM order_items oi\n",
    "JOIN products p ON oi.product_id = p.product_id\n",
    "JOIN product_translation pt ON p.product_category_name = pt.product_category_name\n",
    "GROUP BY category\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "#===Lendo o resultado da query===#\n",
    "df_revenue = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando gráfico de barras com as categorias que mais geram faturamento===#\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=df_revenue, x=\"total_revenue\", y=\"category\")\n",
    "plt.title(\"Top 10 Categorias por Faturamento\")\n",
    "plt.xlabel(\"Faturamento (R$)\")\n",
    "plt.ylabel(\"Categoria\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a84c2",
   "metadata": {},
   "source": [
    "### (e) Estados brasileiros com maior valor médio de pedido\n",
    "- Juntar orders, order_items e customers\n",
    "- Agrupar por customer_state\n",
    "- Calcular a média dos valores dos pedidos (price)\n",
    "- Plotar o valor médio por estado com gráfico de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1807ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Consulta SQL para calcular o valor médio dos pedidos por estado do cliente===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    c.customer_state AS state,\n",
    "    AVG(oi.price) AS avg_order_value\n",
    "FROM orders o\n",
    "JOIN customers c ON o.customer_id = c.customer_id\n",
    "JOIN order_items oi ON o.order_id = oi.order_id\n",
    "GROUP BY state\n",
    "ORDER BY avg_order_value DESC;\n",
    "\"\"\"\n",
    "\n",
    "#===Executando e lendo os dados===#\n",
    "df_avg_order = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d1542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando gráfico mostrando o valor médio por estado brasileiro===#\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=df_avg_order, x=\"avg_order_value\", y=\"state\")\n",
    "plt.title(\"Valor Médio de Pedido por Estado\")\n",
    "plt.xlabel(\"Valor Médio (R$)\")\n",
    "plt.ylabel(\"Estado\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a570262",
   "metadata": {},
   "source": [
    "# ETAPA 3 - Solução de Problemas de Negócio\n",
    "\n",
    "### Subetapa 1: Análise de Retenção  \n",
    "Nesta parte, foi calculado a taxa de clientes recorrentes. Considerando que um cliente recorrente é aquele que fez mais de um pdedio no período analisado  \n",
    "- Agrupar os pedidos por customer_unique_id\n",
    "- Contar quantos pedidos cada cliente fez\n",
    "- Criar uma variável que marca se o cliente é recorrente (mais de 1 pedido)\n",
    "- Calcular a taxa de recorrência (% de clientes que voltaram a comprar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Consulta SQL: agrupando os pedidos por cliente_unique_id===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    c.customer_unique_id,\n",
    "    COUNT(o.order_id) AS num_orders\n",
    "FROM orders o\n",
    "JOIN customers c ON o.customer_id = c.customer_id\n",
    "GROUP BY c.customer_unique_id;\n",
    "\"\"\"\n",
    "\n",
    "#===Executando a query e transformando em DataFrame===#\n",
    "df_retention = pd.read_sql(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d15a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando coluna que indica se o cliente fez mais de um pedido===#\n",
    "df_retention['is_recurring'] = df_retention['num_orders'] > 1  #->True se o cliente tiver feito mais de 1 pedido\n",
    "\n",
    "#===Calculando a taxa de clientes recorrentes===#\n",
    "recurring_rate = df_retention['is_recurring'].mean()  #->Média de valores True = % de recorrentes\n",
    "total_clients = df_retention.shape[0]                  #->Total de clientes únicos\n",
    "recurring_clients = df_retention['is_recurring'].sum() #->Quantidade de recorrentes (True)\n",
    "\n",
    "#===Exibindo os resultados===#\n",
    "print(f\"Clientes totais: {total_clients}\")\n",
    "print(f\"Clientes recorrentes: {recurring_clients}\")\n",
    "print(f\"Taxa de recorrência: {recurring_rate:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d406ae",
   "metadata": {},
   "source": [
    "### Principais insights - Análise de Retenção\n",
    "#### A maioria dos clientes compra apenas uma vez\n",
    "- A taxa de recorrência é baixa, visto o resultado obtido após a consulta, o que mostra que quase todos os clientes fizeram apenas um pedido.\n",
    "- Isso pode indicar que o cliente não tem motivos suficientes para voltar, seja por falta de incentivo, necessidade ou hábito.\n",
    "#### O negócio pode estar dependendo de novos clientes\n",
    "- Como poucos voltam a comprar, o crescimento pode estar baseado em atrair novos clientes o tempo todo, o que geralmente custa mais caro do que manter quem já comprou.\n",
    "### Há espaço para melhorar a fidelização\n",
    "- Se mais clientes fossem incentivados a comprar novamente, as vendas totais poderiam aumentar, mesmo com menos investimento em propaganda.\n",
    "- Algumas ideias seriam: descontos para quem já comprou, envio de e-mails com ofertas personalizadas, ou programas simples de benefícios.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c672ec",
   "metadata": {},
   "source": [
    "### Subetapa 2: Predição de Atraso\n",
    "\n",
    "Aqui vamos criei um modelo simples para prever se um pedido será entregue com atraso.\n",
    "\n",
    "- Considerar atrasado se a data real de entrega > data estimada\n",
    "- Usar variáveis relacionadas ao valor do pedido, pagamento, frete e distância\n",
    "- Treinar um modelo simples com Regressão Logística\n",
    "- Corrigir o desbalanceamento das classes com `class_weight='balanced'`\n",
    "- Avaliar os resultados com métricas de classificação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8989d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Consulta SQL: dados do pedido, frete e pagamento===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    o.order_id,\n",
    "    o.order_purchase_timestamp,\n",
    "    o.order_estimated_delivery_date,\n",
    "    o.order_delivered_customer_date,\n",
    "    oi.freight_value,\n",
    "    oi.price,\n",
    "    op.payment_type,\n",
    "    op.payment_installments,\n",
    "    op.payment_value\n",
    "FROM orders o\n",
    "JOIN order_items oi ON o.order_id = oi.order_id\n",
    "JOIN order_payments op ON o.order_id = op.order_id\n",
    "WHERE o.order_delivered_customer_date IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "df_delay = pd.read_sql(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Convertendo datas para datetime===#\n",
    "df_delay['order_purchase_timestamp'] = pd.to_datetime(df_delay['order_purchase_timestamp'])\n",
    "df_delay['order_estimated_delivery_date'] = pd.to_datetime(df_delay['order_estimated_delivery_date'])\n",
    "df_delay['order_delivered_customer_date'] = pd.to_datetime(df_delay['order_delivered_customer_date'])\n",
    "\n",
    "#===Criando a variável alvo: 1 = pedido atrasado, 0 = no prazo===#\n",
    "df_delay['is_late'] = df_delay['order_delivered_customer_date'] > df_delay['order_estimated_delivery_date']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e92fe0",
   "metadata": {},
   "source": [
    "**Por que escolhi essas variáveis?**\n",
    "\n",
    "- `freight_value`: reflete a complexidade ou distância da entrega\n",
    "- `price`: produtos mais caros podem ter processos logísticos diferentes\n",
    "- `payment_installments`: pode indicar perfil de compra ou urgência\n",
    "- `payment_value`: valor total da compra\n",
    "- `distance_km`: representa o fator logístico mais direto\n",
    "\n",
    "Todas são numéricas, limpas e ajudam a construir um modelo simples, mas significativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Consulta SQL para pegar as coordenadas médias dos CEPs===#\n",
    "query_dist = \"\"\"\n",
    "SELECT \n",
    "    o.order_id,\n",
    "    gc.lat AS customer_lat,\n",
    "    gc.lng AS customer_lng,\n",
    "    gs.lat AS seller_lat,\n",
    "    gs.lng AS seller_lng\n",
    "FROM orders o\n",
    "JOIN customers c ON o.customer_id = c.customer_id\n",
    "JOIN order_items oi ON o.order_id = oi.order_id\n",
    "JOIN sellers s ON oi.seller_id = s.seller_id\n",
    "JOIN geo_avg gc ON c.customer_zip_code_prefix = gc.geolocation_zip_code_prefix\n",
    "JOIN geo_avg gs ON s.seller_zip_code_prefix = gs.geolocation_zip_code_prefix\n",
    "WHERE o.order_delivered_customer_date IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "df_coords = pd.read_sql(query_dist, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354acc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Função para calcular a distância entre dois pontos geográficos===#\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Raio da Terra em km\n",
    "    dlat = radians(lat2 - lat1)\n",
    "    dlon = radians(lon2 - lon1)\n",
    "    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "#===Calculando distância cliente-vendedor para cada linha===#\n",
    "df_coords['distance_km'] = df_coords.apply(\n",
    "    lambda row: haversine(row['customer_lat'], row['customer_lng'], row['seller_lat'], row['seller_lng']),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9dce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Unindo as distâncias com o DataFrame de modelagem===#\n",
    "df_delay = df_delay.merge(df_coords[['order_id', 'distance_km']], on='order_id', how='left')\n",
    "\n",
    "#===Removendo linhas com valores ausentes nas variáveis do modelo===#\n",
    "df_delay = df_delay.dropna(subset=['freight_value', 'price', 'payment_installments', 'payment_value', 'distance_km'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877c5bb",
   "metadata": {},
   "source": [
    "**Por que a remoção de valores ausentes (NaN) foi feita aqui e não na limpeza geral?**\n",
    "\n",
    "A linha `df_delay.dropna(subset=[...])` só foi aplicada depois que selecionamos as colunas específicas do modelo.\n",
    "\n",
    "> Isso porque faz mais sentido remover dados ausentes **quando já sabemos quais variáveis serão usadas**.\n",
    "\n",
    "Se essa remoção tivese acontecido na etapa de limpeza geral, dados importantes poderiam ser excluidos de forma prematura, sem saber se eles seriam realmente necessários para a modelagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33025fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Importando o modelo e ajustando com class_weight='balanced'===#\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#===Selecionando as features e a variável alvo===#\n",
    "features = df_delay[['freight_value', 'price', 'payment_installments', 'payment_value', 'distance_km']]\n",
    "target = df_delay['is_late'].astype(int)\n",
    "\n",
    "#===Separando os dados em treino e teste===#\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')  #-> Força o modelo a dar atenção à classe minoritária (atrasos)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#===Fazendo previsões no teste===#\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#===Avaliação com métricas de classificação===#\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e56900",
   "metadata": {},
   "source": [
    "\n",
    "### O que essas métricas significam:\n",
    "\n",
    "- **Classe 0 = Entrega no prazo**\n",
    "  - `precision 0.94`: entre os que o modelo previu como \"no prazo\", 94% estavam corretos\n",
    "  - `recall 0.63`: o modelo conseguiu encontrar 63% das entregas no prazo\n",
    "\n",
    "- **Classe 1 = Entrega com atraso**\n",
    "  - `precision 0.09`: quando ele prevê atraso, só 9% realmente atrasaram → ainda erra bastante\n",
    "  - `recall 0.48`: mas já consegue identificar **quase metade** dos pedidos que realmente atrasaram\n",
    "\n",
    "- **Acurácia geral = 62%**\n",
    "  - A precissão está boa, mas ainda existem problemas como o desbalanceamento dos dados\n",
    "\n",
    "- **F1-score classe 1 = 0.16**\n",
    "  - Reflete que o modelo ainda **tem dificuldade para acertar os atrasos**\n",
    "\n",
    "---\n",
    "\n",
    "**Possíveis desenvolvimentos:**\n",
    "- Testar outros modelos (como Random Forest)\n",
    "- Explorar técnicas como `SMOTE` ou `undersampling`\n",
    "- Incluir mais variáveis logísticas ou de tempo (ex: tempo de aprovação)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb6a4c9",
   "metadata": {},
   "source": [
    "## Subetapa 3 — Segmentação de Clientes\n",
    "\n",
    "Nesta etapa, utilizei a técnica de clustering (agrupamento) para segmentar os clientes em grupos com comportamentos semelhantes.\n",
    "- Para cada cliente único, calculamos:\n",
    "  - O número total de pedidos realizados (`num_orders`)\n",
    "  - O ticket médio (valor médio gasto por pedido - `avg_ticket`)\n",
    "- Esses dois indicadores foram padronizados para evitar distorções causadas pela escala dos valores.\n",
    "- Utilizamos o algoritmo **KMeans**, com 3 clusters definidos para identificar padrões distintos de consumo.\n",
    "\n",
    "Essa segmentação é útil para definir perfis de clientes e sugerir estratégias de marketing para cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022b2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Consulta SQL para obter número de pedidos e ticket médio por cliente===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    c.customer_unique_id,\n",
    "    COUNT(o.order_id) AS num_orders,\n",
    "    AVG(oi.price) AS avg_ticket\n",
    "FROM customers c\n",
    "JOIN orders o ON c.customer_id = o.customer_id\n",
    "JOIN order_items oi ON o.order_id = oi.order_id\n",
    "GROUP BY c.customer_unique_id;\n",
    "\"\"\"\n",
    "\n",
    "df_segmentation = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Importando bibliotecas para clustering===#\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#===Selecionando colunas para o modelo de cluster===#\n",
    "X = df_segmentation[['num_orders', 'avg_ticket']]\n",
    "\n",
    "#===Padronizando os dados para evitar distorção por escala===#\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#===Aplicando o KMeans com 3 clusters===#\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_segmentation['cluster'] = kmeans.fit_predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ae101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Gráfico de dispersão para visualizar os grupos de clientes===#\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=df_segmentation, x='num_orders', y='avg_ticket', hue='cluster', palette='tab10')\n",
    "plt.title(\"Segmentação de Clientes por Ticket Médio e Nº de Pedidos\")\n",
    "plt.xlabel(\"Número de Pedidos\")\n",
    "plt.ylabel(\"Ticket Médio (R$)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64a83cc",
   "metadata": {},
   "source": [
    "**Perfis identificados pelos clusters:**\n",
    "\n",
    "- **Cluster 0 – Clientes Casuais:**  \n",
    "  Baixo número de pedidos e ticket médio reduzido. Provavelmente são clientes que compraram uma vez e não retornaram.  \n",
    "  ➤ *Ação sugerida:* campanhas de reengajamento (ex: cupons de desconto para 2ª compra).\n",
    "\n",
    "- **Cluster 1 – Compradores Premium:**  \n",
    "  Ticket médio alto, mas com poucos pedidos. Possuem maior poder aquisitivo, mas não se fidelizaram.  \n",
    "  ➤ *Ação sugerida:* ofertas personalizadas, vantagens exclusivas e recomendação de produtos de maior valor.\n",
    "\n",
    "- **Cluster 2 – Clientes Fiéis:**  \n",
    "  Alto volume de pedidos com ticket médio intermediário. Representam o público mais engajado e consistente da base.  \n",
    "  ➤ *Ação sugerida:* programas de fidelidade, benefícios progressivos, acesso antecipado a ofertas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f633b",
   "metadata": {},
   "source": [
    "## Subetapa 4 — Análise de Satisfação\n",
    "\n",
    "Identificar os principais fatores que influenciam a nota de avaliação (`review_score`) que o cliente fornece após a entrega.\n",
    "\n",
    "- Relacionamos a avaliação do cliente com três variáveis:\n",
    "  - **Tempo de entrega** (diferença entre data de compra e data de entrega)\n",
    "  - **Valor do produto** (`price`)\n",
    "  - **Categoria do produto**\n",
    "- Utilizamos visualizações:\n",
    "  - **Boxplots** para entender a distribuição da nota em relação ao tempo de entrega e ao valor\n",
    "  - **Gráfico de calor (heatmap)** cruzando faixas de preço com faixas de tempo de entrega, mostrando os piores e melhores cenários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Consulta SQL para trazer review_score, tempo de entrega, valor e categoria===#\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    r.review_score,\n",
    "    julianday(o.order_delivered_customer_date) - julianday(o.order_purchase_timestamp) AS delivery_time,\n",
    "    oi.price,\n",
    "    p.product_category_name\n",
    "FROM order_reviews r\n",
    "JOIN orders o ON r.order_id = o.order_id\n",
    "JOIN order_items oi ON o.order_id = oi.order_id\n",
    "JOIN products p ON oi.product_id = p.product_id\n",
    "WHERE r.review_score IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "df_reviews = pd.read_sql(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e61a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Visualizando como o tempo de entrega varia conforme a nota dada pelo cliente===#\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(data=df_reviews, x='review_score', y='delivery_time')\n",
    "plt.title(\"Distribuição do Tempo de Entrega por Nota de Avaliação\")\n",
    "plt.xlabel(\"Nota de Avaliação\")\n",
    "plt.ylabel(\"Tempo de Entrega (dias)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae6cd41",
   "metadata": {},
   "source": [
    "- Notas mais baixas (1 e 2) estão associadas a tempos de entrega mais altos.\n",
    "- Quanto mais rápida a entrega, maior a chance de avaliação positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Visualizando se o valor do produto influencia a nota===#\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df_reviews, x='review_score', y='price')\n",
    "plt.title(\"Distribuição do Valor do Produto por Nota de Avaliação\")\n",
    "plt.xlabel(\"Nota de Avaliação\")\n",
    "plt.ylabel(\"Valor do Produto (R$)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f32dba",
   "metadata": {},
   "source": [
    "- O preço do produto parece ter pouca influência com a nota.\n",
    "- Clientes dão notas baixas tanto para compras baratas quanto compras caras, o tempo de entrega possui um peso maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227dad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===Criando faixas categóricas para visualização cruzada===#\n",
    "df_reviews['delivery_range'] = pd.cut(df_reviews['delivery_time'], bins=[0,5,10,15,20,30,100], labels=['0–5','6–10','11–15','16–20','21–30','31+'])\n",
    "df_reviews['price_range'] = pd.cut(df_reviews['price'], bins=[0,50,150,300,600,10000], labels=['até 50', '51–150', '151–300', '301–600', '601+'])\n",
    "\n",
    "#===Criando tabela dinâmica com média das notas===#\n",
    "pivot = df_reviews.pivot_table(index='delivery_range', columns='price_range', values='review_score', aggfunc='mean')\n",
    "\n",
    "#===Plotando o gráfico de calor===#\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(pivot, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "plt.title(\"Nota Média por Faixa de Entrega e Faixa de Preço\")\n",
    "plt.xlabel(\"Faixa de Preço (R$)\")\n",
    "plt.ylabel(\"Tempo de Entrega (dias)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00617edd",
   "metadata": {},
   "source": [
    "**Principais Insights:**\n",
    "\n",
    "- O tempo de entrega é o fator com maior influência na avaliação.\n",
    "- Mesmo produtos baratos têm nota alta se forem entregues rapidamente.\n",
    "- As piores médias de nota ocorrem quando o produto é barato e demora muito para chegar (ex: \"até 50 R$\" entregues em \"31+ dias\").\n",
    "\n",
    "**Ações sugeridas:**\n",
    "- Focar em logística para produtos de menor valor\n",
    "- Gerenciar melhor as expectativas de prazo com o cliente\n",
    "- Monitorar categorias com histórico de demora + nota baixa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
